{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbc785e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: RPi.GPIO not found. GPIO tasks will be simulated.\n",
      "WebRTC VAD not installed.\n",
      "\n",
      "=== Starting Offline Hindi Voice Assistant Dependencies Check ===\n",
      "\n",
      "\n",
      "=== SYSTEM CHECK ===\n",
      "Platform: Windows-10-10.0.26200-SP0\n",
      "Python Version: 3.10.11\n",
      "CPU Cores: 8\n",
      "Logical Cores: 16\n",
      "Total RAM (GB): 15.4\n",
      "System check passed.\n",
      "\n",
      "Optimizing CPU usage...\n",
      "CPU affinity set.\n",
      "CPU optimization complete.\n",
      "\n",
      "Checking ASR models...\n",
      "\n",
      "[OK] coqui_stt found | Size: 45.22 MB\n",
      "[OK] wav2vec2 found | Size: 1203.71 MB\n",
      "[OK] vosk found | Size: 78.28 MB\n",
      "[OK] whisper found | Size: 922.2 MB\n",
      "\n",
      "ASR model check complete.\n",
      "\n",
      "Checking TTS models...\n",
      "\n",
      "[MISSING] System TTS Engine: espeak-ng\n",
      "[MISSING] System TTS Engine: festival\n",
      "\n",
      "TTS model check complete.\n",
      "\n",
      "Checking translation models...\n",
      "\n",
      "[OK] hi-en_model found | Size: 293.8 MB\n",
      "\n",
      "Translation model check complete.\n",
      "\n",
      "Checking ASR libraries...\n",
      "\n",
      "[MISSING] Coqui STT library\n",
      "[OK] Vosk library installed\n",
      "[MISSING] Whisper library\n",
      "\n",
      "ASR library check complete.\n",
      "\n",
      "Checking TTS libraries...\n",
      "\n",
      "[OK] sounddevice library installed\n",
      "[OK] pyttsx3 installed (fallback TTS available)\n",
      "\n",
      "TTS library check complete.\n",
      "\n",
      "Checking models...\n",
      "Intent model found: models/intent_model_optimized.joblib\n",
      "Model files verified.\n",
      "\n",
      "Checking audio devices...\n",
      "Audio devices OK.\n",
      "\n",
      "Loading ASR model...\n",
      "Error loading Coqui STT model: No module named 'stt'\n",
      "Loading intent model...\n",
      "Intent model loaded.\n",
      "\n",
      "Loading TTS model...\n",
      "eSpeak-NG TTS model loaded.\n",
      "Loading translation model...\n",
      "Loading Hindi → English Translator...\n",
      "All model checks completed.\n",
      "\n",
      "Initialization complete.\n",
      "System ready.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Offline Hindi Voice Assistant\n",
    "Optimized for Raspberry Pi 4 (4GB RAM)\n",
    "CPU-only | Quantized ASR | Rule-based Intent | eSpeak TTS\n",
    "\"\"\"\n",
    "\n",
    "# ==========================================================\n",
    "# STANDARD LIBRARIES\n",
    "# ==========================================================\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import platform\n",
    "import datetime\n",
    "import multiprocessing as mp\n",
    "import threading\n",
    "import queue\n",
    "import subprocess\n",
    "import psutil\n",
    "import shutil\n",
    "import warnings\n",
    "import ctypes\n",
    "\n",
    "# ==========================================================\n",
    "# --- COMPULSORY LIBS CHECK ---\n",
    "# ==========================================================\n",
    "try:\n",
    "    import RPi.GPIO as GPIO\n",
    "    GPIO_AVAILABLE = True\n",
    "    GPIO_FAN = 17\n",
    "    GPIO_LIGHT = 27\n",
    "except ImportError:\n",
    "    GPIO_AVAILABLE = False\n",
    "    if not os.environ.get(\"GPIO_WARNED\"):\n",
    "        print(\"Warning: RPi.GPIO not found. GPIO tasks will be simulated.\")\n",
    "        os.environ[\"GPIO_WARNED\"] = \"1\"\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# SCIENTIFIC / ML LIBRARIES\n",
    "# ==========================================================\n",
    "try:\n",
    "    import torch\n",
    "except ImportError:\n",
    "    print(\"Torch not installed.\")\n",
    "\n",
    "try:\n",
    "    from transformers import Wav2Vec2Processor, AutoModelForCTC, AutoTokenizer, AutoModelForSeq2SeqLM ,MarianMTModel, MarianTokenizer\n",
    "except ImportError:\n",
    "    print(\"Transformer not installed.\")\n",
    "\n",
    "try:\n",
    "    import numpy as np\n",
    "except ImportError:\n",
    "    print(\"NumPy not installed.\")\n",
    "    # #\n",
    "\n",
    "try:\n",
    "    import joblib\n",
    "except ImportError:\n",
    "    print(\"Joblib not installed.\")\n",
    "    # #\n",
    "\n",
    "try:\n",
    "    import onnxruntime as ort\n",
    "except ImportError:\n",
    "    print(\"ONNX Runtime not installed.\")\n",
    "    # #\n",
    "\n",
    "try:\n",
    "    from sklearn.pipeline import Pipeline\n",
    "except ImportError:\n",
    "    print(\"Scikit-learn not installed.\")\n",
    "    # #\n",
    "\n",
    "# ==========================================================\n",
    "# AUDIO LIBRARIES\n",
    "# ==========================================================\n",
    "try:\n",
    "    import pyaudio\n",
    "except ImportError:\n",
    "    print(\"PyAudio not installed.\")\n",
    "    # #\n",
    "\n",
    "try:\n",
    "    import webrtcvad\n",
    "except ImportError:\n",
    "    print(\"WebRTC VAD not installed.\")\n",
    "    # #\n",
    "\n",
    "# ==========================================================\n",
    "# CONFIGURATION\n",
    "# ==========================================================\n",
    "\n",
    "INTENT_MODEL_PATH = \"models/intent_model_optimized.joblib\"\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "CHANNELS = 1\n",
    "CHUNK = 320  # 20 ms frames at 16kHz\n",
    "VAD_MODE = 2\n",
    "\n",
    "# ==========================================================\n",
    "# SYSTEM CHECKS\n",
    "# ==========================================================\n",
    "\n",
    "def check_system():\n",
    "    print(\"\\n=== SYSTEM CHECK ===\")\n",
    "\n",
    "    print(\"Platform:\", platform.platform())\n",
    "    print(\"Python Version:\", platform.python_version())\n",
    "    print(\"CPU Cores:\", psutil.cpu_count(logical=False))\n",
    "    print(\"Logical Cores:\", psutil.cpu_count())\n",
    "    print(\"Total RAM (GB):\", round(psutil.virtual_memory().total / (1024**3), 2))\n",
    "\n",
    "    if psutil.virtual_memory().total < 3 * (1024**3):\n",
    "        print(\"Warning: RAM may be insufficient.\")\n",
    "\n",
    "    print(\"System check passed.\\n\")\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# CPU OPTIMIZATION\n",
    "# ==========================================================\n",
    "\n",
    "def optimize_cpu():\n",
    "    print(\"Optimizing CPU usage...\")\n",
    "\n",
    "    # Limit OpenMP threads for ONNX Runtime\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = \"2\"\n",
    "    os.environ[\"MKL_NUM_THREADS\"] = \"2\"\n",
    "\n",
    "    # Pin main process to specific cores (0,1,2)\n",
    "    try:\n",
    "        p = psutil.Process(os.getpid())\n",
    "        p.cpu_affinity([0, 1, 2])\n",
    "        print(\"CPU affinity set.\")\n",
    "    except Exception as e:\n",
    "        print(\"CPU affinity not supported:\", e)\n",
    "\n",
    "    print(\"CPU optimization complete.\\n\")\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# MODEL CHECK\n",
    "# ==========================================================\n",
    "\n",
    "def check_intent_model():\n",
    "    print(\"Checking models...\")\n",
    "\n",
    "    try :\n",
    "        os.path.exists(INTENT_MODEL_PATH)\n",
    "        print(f\"Intent model found: {INTENT_MODEL_PATH}\")\n",
    "    except Exception as e:\n",
    "        print(\"Model Not found\")\n",
    "        # #\n",
    "\n",
    "    print(\"Model files verified.\\n\")\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# REQUIRED MODELS CONFIGURATION\n",
    "# ==========================================================\n",
    "\n",
    "ASR_MODELS = {\n",
    "    \"coqui_stt\": \"models\\ASR_STT\\coqui_stt\\coqui_stt_asr_model.tflite\",\n",
    "    \"wav2vec2\": \"models\\ASR_STT\\IndicWav2Vec2\\pytorch_model.bin\",\n",
    "    # \"wav2vec2\": \"models\\ASR_STT\\wav2vec2\\model.safetensors\",\n",
    "    \"vosk\": \"models/ASR_STT/vosk-model-small-hi-0.22/vosk-model-small-hi-0.22\",\n",
    "    \"whisper\": \"models\\ASR_STT\\Wisper-small\\model.safetensors\"\n",
    "}\n",
    "\n",
    "ASR_model_select=\"coqui_stt\"\n",
    "\n",
    "# System binaries\n",
    "SYSTEM_TTS_ENGINES = {\n",
    "    \"espeak-ng\": \"models/espeak-ng\",\n",
    "    \"festival\": \"models/festival\"\n",
    "}\n",
    "\n",
    "TTS_model_select=\"espeak-ng\"\n",
    "\n",
    "TRANSLATION_MODEL={\n",
    "    \"hi-en_model\": \"models\\Translation_model\\hi-en_model\"\n",
    "}\n",
    "\n",
    "TRANSLATION_model_select=\"hi-en_model\"\n",
    "\n",
    "# ==========================================================\n",
    "# FILE SIZE UTILITY\n",
    "# ==========================================================\n",
    "\n",
    "def get_size_mb(path):\n",
    "    if os.path.isfile(path):\n",
    "        return round(os.path.getsize(path) / (1024**2), 2)\n",
    "    elif os.path.isdir(path):\n",
    "        total = 0\n",
    "        for root, _, files in os.walk(path):\n",
    "            for f in files:\n",
    "                total += os.path.getsize(os.path.join(root, f))\n",
    "        return round(total / (1024**2), 2)\n",
    "    return 0\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# ASR MODEL CHECK\n",
    "# ==========================================================\n",
    "\n",
    "def check_asr_models():\n",
    "    print(\"Checking ASR models...\\n\")\n",
    "\n",
    "    for name, path in ASR_MODELS.items():\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"[MISSING] {name} → {path}\")\n",
    "        else:\n",
    "            size = get_size_mb(path)\n",
    "            print(f\"[OK] {name} found | Size: {size} MB\")\n",
    "\n",
    "    print(\"\\nASR model check complete.\\n\")\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# TTS MODEL CHECK\n",
    "# ==========================================================\n",
    "\n",
    "def check_tts_models():\n",
    "    print(\"Checking TTS models...\\n\")\n",
    "\n",
    "    # System binaries check\n",
    "    for name, cmd in SYSTEM_TTS_ENGINES.items():\n",
    "        if shutil.which(cmd) is None:\n",
    "            print(f\"[MISSING] System TTS Engine: {name}\")\n",
    "        else:\n",
    "            print(f\"[OK] {name} installed\")\n",
    "\n",
    "    print(\"\\nTTS model check complete.\\n\")\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# LIBRARY CHECK FOR ASR ENGINES\n",
    "# ==========================================================\n",
    "\n",
    "def check_asr_libraries():\n",
    "    print(\"Checking ASR libraries...\\n\")\n",
    "\n",
    "    try:\n",
    "        import stt\n",
    "        print(\"[OK] Coqui STT library installed\")\n",
    "    except ImportError:\n",
    "        print(\"[MISSING] Coqui STT library\")\n",
    "\n",
    "    try:\n",
    "        import vosk \n",
    "        from vosk import Model, KaldiRecognizer\n",
    "        print(\"[OK] Vosk library installed\")\n",
    "    except ImportError:\n",
    "        print(\"[MISSING] Vosk library\")\n",
    "\n",
    "    try:\n",
    "        import whisper\n",
    "        print(\"[OK] Whisper library installed\")\n",
    "    except ImportError:\n",
    "        print(\"[MISSING] Whisper library\")\n",
    "\n",
    "    print(\"\\nASR library check complete.\\n\")\n",
    "\n",
    "# ==========================================================\n",
    "# TRANSLATION MODEL CHECK\n",
    "# ==========================================================\n",
    "\n",
    "def check_translation_models():\n",
    "    print(\"Checking translation models...\\n\") \n",
    "    for name, path in TRANSLATION_MODEL.items():\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"[MISSING] {name} → {path}\")\n",
    "        else:\n",
    "            size = get_size_mb(path)\n",
    "            print(f\"[OK] {name} found | Size: {size} MB\")\n",
    "\n",
    "    print(\"\\nTranslation model check complete.\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# LIBRARY CHECK FOR ASR ENGINES\n",
    "# ==========================================================\n",
    "\n",
    "def check_tts_libraries():\n",
    "    print(\"Checking TTS libraries...\\n\")\n",
    "    try:\n",
    "        import sounddevice\n",
    "        print(\"[OK] sounddevice library installed\")\n",
    "    except ImportError:\n",
    "        print(\"[WARNING] sounddevice not installed (audio playback may fail)\")\n",
    "\n",
    "    try:\n",
    "        import pyttsx3\n",
    "        print(\"[OK] pyttsx3 installed (fallback TTS available)\")\n",
    "    except ImportError:\n",
    "        print(\"[INFO] pyttsx3 not installed (optional)\")\n",
    "\n",
    "    print(\"\\nTTS library check complete.\\n\")\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# AUDIO DEVICE CHECK\n",
    "# ==========================================================\n",
    "\n",
    "def check_audio_devices():\n",
    "    print(\"Checking audio devices...\")\n",
    "\n",
    "    pa = pyaudio.PyAudio()\n",
    "\n",
    "    input_found = False\n",
    "    output_found = False\n",
    "\n",
    "    for i in range(pa.get_device_count()):\n",
    "        dev = pa.get_device_info_by_index(i)\n",
    "        if dev[\"maxInputChannels\"] > 0:\n",
    "            input_found = True\n",
    "        if dev[\"maxOutputChannels\"] > 0:\n",
    "            output_found = True\n",
    "\n",
    "    pa.terminate()\n",
    "\n",
    "    if not input_found:\n",
    "        print(\"No microphone detected.\")\n",
    "        # #\n",
    "\n",
    "    if not output_found:\n",
    "        print(\"No speaker detected.\")\n",
    "        # #\n",
    "\n",
    "    print(\"Audio devices OK.\\n\")\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# ASR MODEL PRELOAD \n",
    "# ==========================================================\n",
    "\n",
    "def preload_asr_model():\n",
    "    print(\"Loading ASR model...\")\n",
    "    asr_model_path = ASR_MODELS.get(ASR_model_select)\n",
    "    \n",
    "    if ASR_model_select == \"coqui_stt\":\n",
    "        # Load Coqui STT (TensorFlow Lite)\n",
    "        try:\n",
    "            import stt\n",
    "            session = stt.Model(asr_model_path)\n",
    "            print(\"Coqui STT model loaded.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading Coqui STT model: {e}\")\n",
    "            return None\n",
    "\n",
    "    elif ASR_model_select == \"wav2vec2\":\n",
    "        # Load Wav2Vec2 (PyTorch-based)\n",
    "        try:\n",
    "            model = torch.load(asr_model_path)\n",
    "            print(\"Wav2Vec2 model loaded.\")\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading Wav2Vec2 model: {e}\")\n",
    "            return None\n",
    "\n",
    "    elif ASR_model_select == \"vosk\":\n",
    "        # Load Vosk (Kaldi-based)\n",
    "        try:\n",
    "            model = Model(asr_model_path)\n",
    "            recognizer = KaldiRecognizer(model, SAMPLE_RATE)\n",
    "            print(\"Vosk model loaded.\")\n",
    "            return recognizer\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading Vosk model: {e}\")\n",
    "            return None\n",
    "\n",
    "    elif ASR_model_select == \"whisper\":\n",
    "        # Load Whisper (OpenAI)\n",
    "        try:\n",
    "            import whisper\n",
    "            model = whisper.load_model(asr_model_path)\n",
    "            print(\"Whisper model loaded.\")\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading Whisper model: {e}\")\n",
    "            return None\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# TTS MODELS PRELOAD\n",
    "# ==========================================================\n",
    "def preload_tts_model():\n",
    "    print(\"Loading TTS model...\")\n",
    "\n",
    "    if TTS_model_select == \"espeak-ng\":\n",
    "        try:\n",
    "            # Check if espeak-ng is installed and available\n",
    "            if shutil.which(\"espeak-ng\") is not None:\n",
    "                print(\"eSpeak-NG TTS model loaded.\")\n",
    "                return \"espeak-ng\"\n",
    "            else:\n",
    "                print(\"[MISSING] eSpeak-NG TTS engine not found.\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading eSpeak-NG: {e}\")\n",
    "            return None\n",
    "\n",
    "    elif TTS_model_select == \"festival\":\n",
    "        try:\n",
    "            # Check if Festival is installed and available\n",
    "            if shutil.which(\"festival\") is not None:\n",
    "                print(\"Festival TTS model loaded.\")\n",
    "                return \"festival\"\n",
    "            else:\n",
    "                print(\"[MISSING] Festival TTS engine not found.\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading Festival: {e}\")\n",
    "            return None\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# INTENT MODEL PRELOAD\n",
    "# ==========================================================\n",
    "\n",
    "def preload_intent_model():\n",
    "    print(\"Loading intent model...\")\n",
    "    model = joblib.load(INTENT_MODEL_PATH)\n",
    "    print(\"Intent model loaded.\\n\")\n",
    "    return model\n",
    "\n",
    "# ==========================================================\n",
    "# TRANSLATION MODEL PRELOAD\n",
    "# ==========================================================\n",
    "\n",
    "def preload_translation_model():\n",
    "    print(\"Loading translation model...\")\n",
    "    translation_model_path = TRANSLATION_MODEL.get(TRANSLATION_model_select)\n",
    "    tokenizer = MarianTokenizer.from_pretrained(translation_model_path)\n",
    "    translator = MarianMTModel.from_pretrained(translation_model_path)\n",
    "    translator.eval()\n",
    "    print(\"Hindi → English Translator model loaded. \\n\")\n",
    "    return tokenizer,translator\n",
    "\n",
    "# ==========================================================\n",
    "# MAIN INITIALIZATION\n",
    "# ==========================================================\n",
    "\n",
    "def initialize():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    check_system()\n",
    "    optimize_cpu()\n",
    "    check_asr_models()\n",
    "    check_tts_models()\n",
    "    check_translation_models()\n",
    "    check_asr_libraries()\n",
    "    check_tts_libraries()\n",
    "    check_intent_model()\n",
    "    check_audio_devices()\n",
    "\n",
    "    asr_session = preload_asr_model()\n",
    "    intent_model = preload_intent_model()\n",
    "    tts_model = preload_tts_model()\n",
    "    tokenizer,translator =preload_translation_model()\n",
    "    print(\"All model checks completed.\\n\")\n",
    "    return asr_session, intent_model\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# ENTRY POINT\n",
    "# ==========================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mp.set_start_method(\"spawn\", force=True)\n",
    "\n",
    "    print(\"\\n=== Starting Offline Hindi Voice Assistant Dependencies Check ===\\n\")\n",
    "\n",
    "    asr_session, intent_model = initialize()\n",
    "\n",
    "    print(\"Initialization complete.\")\n",
    "    print(\"System ready.\\n\")\n",
    "\n",
    "    # Pipeline execution will start here (next stage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae9faba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
