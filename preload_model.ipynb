{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8141e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# GLOBAL PERFORMANCE CONTROL (SET BEFORE ML IMPORTS)\n",
    "# ==========================================================\n",
    "import os\n",
    "import shutil\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"2\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"2\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"TRANSFORMERS_NO_ADVISORY_WARNINGS\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cc1208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "INTENT_MODEL_PATH = \"models/intent_model_optimized.joblib\"\n",
    "\n",
    "ASR_MODELS = {\n",
    "    \"coqui_stt\": \"models\\ASR_STT\\coqui_stt\\coqui_stt_asr_model.tflite\",\n",
    "    \"wav2vec2\": \"models\\ASR_STT\\IndicWav2Vec2\\pytorch_model.bin\",\n",
    "    # \"wav2vec2\": \"models\\ASR_STT\\wav2vec2\\model.safetensors\",\n",
    "    \"vosk\": \"models/ASR_STT/vosk-model-small-hi-0.22/vosk-model-small-hi-0.22\",\n",
    "    \"whisper\": \"models\\ASR_STT\\Wisper-small\\model.safetensors\"\n",
    "}\n",
    "\n",
    "ASR_model_select=\"coqui_stt\"\n",
    "\n",
    "# System binaries\n",
    "SYSTEM_TTS_ENGINES = {\n",
    "    \"espeak-ng\": \"models/espeak-ng\",\n",
    "    \"festival\": \"models/festival\"\n",
    "}\n",
    "\n",
    "TTS_model_select=\"espeak-ng\"\n",
    "\n",
    "TRANSLATION_MODEL={\n",
    "    \"hi-en_model\": \"models\\Translation_model\\hi-en_model\"\n",
    "}\n",
    "\n",
    "TRANSLATION_model_select=\"hi-en_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b582687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preload_asr_model():\n",
    "    print(\"Loading ASR model (Optimized)...\")\n",
    "\n",
    "    asr_model_path = ASR_MODELS.get(ASR_model_select)\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # COQUI STT (TFLite - Already Quantized)\n",
    "    # ------------------------------------------------------\n",
    "    if ASR_model_select == \"coqui_stt\":\n",
    "        try:\n",
    "            import stt  # import only if selected\n",
    "            model = stt.Model(asr_model_path)\n",
    "            print(\"✔ Coqui STT (TFLite Quantized) Loaded\")\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            print(\"ASR Load Error:\", e)\n",
    "            return None\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # WAV2VEC2 (Dynamic Quantization)\n",
    "    # ------------------------------------------------------\n",
    "    elif ASR_model_select == \"wav2vec2\":\n",
    "        try:\n",
    "            import torch\n",
    "            from transformers import Wav2Vec2ForCTC\n",
    "\n",
    "            torch.set_num_threads(2)\n",
    "            torch.set_grad_enabled(False)\n",
    "\n",
    "            model = Wav2Vec2ForCTC.from_pretrained(\n",
    "                asr_model_path,\n",
    "                local_files_only=True\n",
    "            )\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            # Dynamic INT8 Quantization\n",
    "            model = torch.quantization.quantize_dynamic(\n",
    "                model,\n",
    "                {torch.nn.Linear},\n",
    "                dtype=torch.qint8\n",
    "            )\n",
    "\n",
    "            print(\"✔ Wav2Vec2 (Dynamic INT8 Quantized) Loaded\")\n",
    "            return model\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"ASR Load Error:\", e)\n",
    "            return None\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # VOSK (Already Lightweight Kaldi Model)\n",
    "    # ------------------------------------------------------\n",
    "    elif ASR_model_select == \"vosk\":\n",
    "        try:\n",
    "            from vosk import Model, KaldiRecognizer\n",
    "\n",
    "            model = Model(asr_model_path)\n",
    "            recognizer = KaldiRecognizer(model, SAMPLE_RATE)\n",
    "\n",
    "            print(\"✔ Vosk Lightweight Model Loaded\")\n",
    "            return recognizer\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"ASR Load Error:\", e)\n",
    "            return None\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # WHISPER (CPU Quantized)\n",
    "    # ------------------------------------------------------\n",
    "    elif ASR_model_select == \"whisper\":\n",
    "        try:\n",
    "            import whisper\n",
    "            model = whisper.load_model(\n",
    "                \"small\",\n",
    "                device=\"cpu\"\n",
    "            )\n",
    "\n",
    "            print(\"✔ Whisper CPU Model Loaded\")\n",
    "            return model\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"ASR Load Error:\", e)\n",
    "            return None\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "894889a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preload_intent_model():\n",
    "    print(\"Loading Intent Model (Optimized)...\")\n",
    "\n",
    "    try:\n",
    "        import joblib\n",
    "        model = joblib.load(INTENT_MODEL_PATH)\n",
    "        print(\"✔ Intent Model Loaded\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(\"Intent Load Error:\", e)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f4baa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preload_tts_model():\n",
    "    print(\"Loading TTS Engine...\")\n",
    "\n",
    "    if TTS_model_select == \"espeak-ng\":\n",
    "        if shutil.which(\"espeak-ng\"):\n",
    "            print(\"✔ eSpeak-NG Ready (System Level)\")\n",
    "            return \"espeak-ng\"\n",
    "        else:\n",
    "            print(\"✖ eSpeak-NG Not Found\")\n",
    "            return None\n",
    "\n",
    "    elif TTS_model_select == \"festival\":\n",
    "        if shutil.which(\"festival\"):\n",
    "            print(\"✔ Festival Ready (System Level)\")\n",
    "            return \"festival\"\n",
    "        else:\n",
    "            print(\"✖ Festival Not Found\")\n",
    "            return None\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3ff8f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preload_translation_model():\n",
    "    print(\"Loading Translation Model (Optimized)...\")\n",
    "\n",
    "    translation_model_path = TRANSLATION_MODEL.get(TRANSLATION_model_select)\n",
    "\n",
    "    try:\n",
    "        import torch\n",
    "        from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "        torch.set_num_threads(2)\n",
    "        torch.set_grad_enabled(False)\n",
    "\n",
    "        tokenizer = MarianTokenizer.from_pretrained(\n",
    "            translation_model_path,\n",
    "            local_files_only=True\n",
    "        )\n",
    "\n",
    "        model = MarianMTModel.from_pretrained(\n",
    "            translation_model_path,\n",
    "            local_files_only=True\n",
    "        )\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        # Dynamic Quantization\n",
    "        model = torch.quantization.quantize_dynamic(\n",
    "            model,\n",
    "            {torch.nn.Linear},\n",
    "            dtype=torch.qint8\n",
    "        )\n",
    "\n",
    "        print(\"✔ MarianMT (Dynamic INT8 Quantized) Loaded\")\n",
    "        return tokenizer, model\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Translation Load Error:\", e)\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b55a9261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting Offline Hindi Voice Assistant Preload ===\n",
      "\n",
      "Loading ASR model (Optimized)...\n",
      "ASR Load Error: No module named 'stt'\n",
      "Loading Intent Model (Optimized)...\n",
      "✔ Intent Model Loaded\n",
      "Loading TTS Engine...\n",
      "✔ eSpeak-NG Ready (System Level)\n",
      "Loading Translation Model (Optimized)...\n",
      "✔ MarianMT (Dynamic INT8 Quantized) Loaded\n",
      "All model checks completed.\n",
      "\n",
      "Initialization complete.\n",
      "System ready.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import multiprocessing as mp\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mp.set_start_method(\"spawn\", force=True)\n",
    "\n",
    "    print(\"\\n=== Starting Offline Hindi Voice Assistant Preload ===\\n\")\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    asr_session = preload_asr_model()\n",
    "    intent_model = preload_intent_model()\n",
    "    tts_model = preload_tts_model()\n",
    "    tokenizer,translator =preload_translation_model()\n",
    "    print(\"All model checks completed.\\n\")\n",
    "    print(\"Initialization complete.\")\n",
    "    print(\"System ready.\\n\")\n",
    "\n",
    "    # Pipeline execution will start here (next stage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32ad8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
