{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c4db8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Offline Hindi Voice Assistant\n",
    "Direct Import Version\n",
    "No Verification | No Checking | No Safety Guards\n",
    "\"\"\"\n",
    "\n",
    "# ==========================================================\n",
    "# STANDARD LIBRARIES\n",
    "# ==========================================================\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import platform\n",
    "import datetime\n",
    "import multiprocessing as mp\n",
    "import threading\n",
    "import queue\n",
    "import subprocess\n",
    "import psutil\n",
    "import shutil\n",
    "import warnings\n",
    "import ctypes\n",
    "\n",
    "# ==========================================================\n",
    "# RASPBERRY PI GPIO\n",
    "# ==========================================================\n",
    "# import RPi.GPIO as GPIO\n",
    "GPIO_FAN = 17\n",
    "GPIO_LIGHT = 27\n",
    "\n",
    "# ==========================================================\n",
    "# SCIENTIFIC / ML LIBRARIES\n",
    "# ==========================================================\n",
    "import torch\n",
    "import numpy as np\n",
    "import joblib\n",
    "import onnxruntime as ort\n",
    "\n",
    "from transformers import (\n",
    "    Wav2Vec2Processor,\n",
    "    AutoModelForCTC,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    MarianMTModel,\n",
    "    MarianTokenizer\n",
    ")\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# ==========================================================\n",
    "# ASR LIBRARIES\n",
    "# ==========================================================\n",
    "import stt\n",
    "import vosk\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import whisper\n",
    "\n",
    "# ==========================================================\n",
    "# AUDIO LIBRARIES\n",
    "# ==========================================================\n",
    "import pyaudio\n",
    "import webrtcvad\n",
    "import sounddevice\n",
    "import pyttsx3\n",
    "\n",
    "# ==========================================================\n",
    "# CONFIGURATION\n",
    "# ==========================================================\n",
    "INTENT_MODEL_PATH = \"models/intent_model_optimized.joblib\"\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "CHANNELS = 1\n",
    "CHUNK = 320\n",
    "VAD_MODE = 2\n",
    "\n",
    "# ==========================================================\n",
    "# MODEL DEFINITIONS\n",
    "# ==========================================================\n",
    "\n",
    "ASR_MODELS = {\n",
    "    \"coqui_stt\": \"models\\ASR_STT\\coqui_stt\\coqui_stt_asr_model.tflite\",\n",
    "    \"wav2vec2\": \"models\\ASR_STT\\IndicWav2Vec2\\pytorch_model.bin\",\n",
    "    # \"wav2vec2\": \"models\\ASR_STT\\wav2vec2\\model.safetensors\",\n",
    "    \"vosk\": \"models/ASR_STT/vosk-model-small-hi-0.22/vosk-model-small-hi-0.22\",\n",
    "    \"whisper\": \"models\\ASR_STT\\Wisper-small\\model.safetensors\"\n",
    "}\n",
    "\n",
    "ASR_model_select=\"coqui_stt\"\n",
    "\n",
    "# System binaries\n",
    "SYSTEM_TTS_ENGINES = {\n",
    "    \"espeak-ng\": \"models/espeak-ng\",\n",
    "    \"festival\": \"models/festival\"\n",
    "}\n",
    "\n",
    "TTS_model_select=\"espeak-ng\"\n",
    "\n",
    "TRANSLATION_MODEL={\n",
    "    \"hi-en_model\": \"models\\Translation_model\\hi-en_model\"\n",
    "}\n",
    "\n",
    "TRANSLATION_model_select=\"hi-en_model\"\n",
    "\n",
    "# ==========================================================\n",
    "# ASR MODEL PRELOAD \n",
    "# ==========================================================\n",
    "\n",
    "def preload_asr_model():\n",
    "    print(\"Loading ASR model...\")\n",
    "    asr_model_path = ASR_MODELS.get(ASR_model_select)\n",
    "    \n",
    "    if ASR_model_select == \"coqui_stt\":\n",
    "        # Load Coqui STT (TensorFlow Lite)\n",
    "        try:\n",
    "            import stt\n",
    "            session = stt.Model(asr_model_path)\n",
    "            print(\"Coqui STT model loaded.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading Coqui STT model: {e}\")\n",
    "            return None\n",
    "\n",
    "    elif ASR_model_select == \"wav2vec2\":\n",
    "        # Load Wav2Vec2 (PyTorch-based)\n",
    "        try:\n",
    "            model = torch.load(asr_model_path)\n",
    "            print(\"Wav2Vec2 model loaded.\")\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading Wav2Vec2 model: {e}\")\n",
    "            return None\n",
    "\n",
    "    elif ASR_model_select == \"vosk\":\n",
    "        # Load Vosk (Kaldi-based)\n",
    "        try:\n",
    "            model = Model(asr_model_path)\n",
    "            recognizer = KaldiRecognizer(model, SAMPLE_RATE)\n",
    "            print(\"Vosk model loaded.\")\n",
    "            return recognizer\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading Vosk model: {e}\")\n",
    "            return None\n",
    "\n",
    "    elif ASR_model_select == \"whisper\":\n",
    "        # Load Whisper (OpenAI)\n",
    "        try:\n",
    "            import whisper\n",
    "            model = whisper.load_model(asr_model_path)\n",
    "            print(\"Whisper model loaded.\")\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading Whisper model: {e}\")\n",
    "            return None\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# TTS MODELS PRELOAD\n",
    "# ==========================================================\n",
    "def preload_tts_model():\n",
    "    print(\"Loading TTS model...\")\n",
    "\n",
    "    if TTS_model_select == \"espeak-ng\":\n",
    "        try:\n",
    "            # Check if espeak-ng is installed and available\n",
    "            if shutil.which(\"espeak-ng\") is not None:\n",
    "                print(\"eSpeak-NG TTS model loaded.\")\n",
    "                return \"espeak-ng\"\n",
    "            else:\n",
    "                print(\"[MISSING] eSpeak-NG TTS engine not found.\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading eSpeak-NG: {e}\")\n",
    "            return None\n",
    "\n",
    "    elif TTS_model_select == \"festival\":\n",
    "        try:\n",
    "            # Check if Festival is installed and available\n",
    "            if shutil.which(\"festival\") is not None:\n",
    "                print(\"Festival TTS model loaded.\")\n",
    "                return \"festival\"\n",
    "            else:\n",
    "                print(\"[MISSING] Festival TTS engine not found.\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading Festival: {e}\")\n",
    "            return None\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# INTENT MODEL PRELOAD\n",
    "# ==========================================================\n",
    "\n",
    "def preload_intent_model():\n",
    "    print(\"Loading intent model...\")\n",
    "    model = joblib.load(INTENT_MODEL_PATH)\n",
    "    print(\"Intent model loaded.\\n\")\n",
    "    return model\n",
    "\n",
    "# ==========================================================\n",
    "# TRANSLATION MODEL PRELOAD\n",
    "# ==========================================================\n",
    "\n",
    "def preload_translation_model():\n",
    "    print(\"Loading translation model...\")\n",
    "    translation_model_path = TRANSLATION_MODEL.get(TRANSLATION_model_select)\n",
    "    tokenizer = MarianTokenizer.from_pretrained(translation_model_path)\n",
    "    translator = MarianMTModel.from_pretrained(translation_model_path)\n",
    "    translator.eval()\n",
    "    print(\"Hindi → English Translator model loaded. \\n\")\n",
    "    return tokenizer,translator\n",
    "\n",
    "# ==========================================================\n",
    "# START\n",
    "# ==========================================================\n",
    "if __name__ == \"__main__\":\n",
    "    mp.set_start_method(\"spawn\", force=True)\n",
    "    asr_session = preload_asr_model()\n",
    "    intent_model = preload_intent_model()\n",
    "    tts_model = preload_tts_model()\n",
    "    tokenizer,translator =preload_translation_model()\n",
    "    print(\"All libraries imported successfully.\")\n",
    "    print(\"Models loaded.\")\n",
    "    print(\"System ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18fb0d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies_check\n",
    "# import kleidiAI_system_check\n",
    "# import qwen_llm\n",
    "# import intent_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50ee6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "WAKE_WORDS = [\n",
    "    \"hello assistant\",\n",
    "    \"assistant\",\n",
    "    \"सुनो\",\n",
    "    \"नमस्ते असिस्टेंट\",\n",
    "    \"hello\",\n",
    "    \"namaste\",\n",
    "    \"दोस्त\", \n",
    "    \"सुनो दोस्त\",\n",
    "    \"नमस्ते\",\n",
    "    \"नमस्ते कल्पना\",\n",
    "    \"कल्पना\",\n",
    "    \"kalpana\"\n",
    "]\n",
    "\n",
    "SLEEP_WORDS = [\n",
    "    \"अलविदा दोस्त\",\n",
    "    \"सो जाओ दोस्त\",\n",
    "    \"ALVIDA\",\n",
    "    \"BYE\",\n",
    "    \"सो जाओ\",\n",
    "    \"रुको\",\n",
    "    \"stop\",\n",
    "    \"go to sleep\",\n",
    "    \"बंद करो\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc09d898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# ASSISTANT STATE CONTROL\n",
    "# ==========================================================\n",
    "\n",
    "# Assistant states\n",
    "IDLE = 0\n",
    "ACTIVE = 1\n",
    "\n",
    "class OfflineAssistant:\n",
    "\n",
    "    def __init__(self, asr_session, intent_model):\n",
    "        self.asr_session = asr_session\n",
    "        self.intent_model = intent_model\n",
    "\n",
    "        self.state = IDLE\n",
    "        self.last_active_time = 0\n",
    "        self.active_timeout = 20  # seconds before auto-sleep\n",
    "\n",
    "        self.audio_queue = queue.Queue(maxsize=10)\n",
    "        self.running = True\n",
    "\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "        print(\"Assistant initialized.\")\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # WAKE WORD CHECK\n",
    "    # ------------------------------------------------------\n",
    "    def check_wake_word(self, transcript):\n",
    "        transcript = transcript.lower()\n",
    "        for word in WAKE_WORDS:\n",
    "            if word in transcript:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # SLEEP WORD CHECK\n",
    "    # ------------------------------------------------------\n",
    "    def check_sleep_word(self, transcript):\n",
    "        transcript = transcript.lower()\n",
    "        for word in SLEEP_WORDS:\n",
    "            if word in transcript:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # STATE TRANSITION\n",
    "    # ------------------------------------------------------\n",
    "    def activate(self):\n",
    "        with self.lock:\n",
    "            self.state = ACTIVE\n",
    "            self.last_active_time = time.time()\n",
    "            print(\"[STATE] ACTIVE\")\n",
    "\n",
    "    def deactivate(self):\n",
    "        with self.lock:\n",
    "            self.state = IDLE\n",
    "            print(\"[STATE] IDLE\")\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # AUTO TIMEOUT\n",
    "    # ------------------------------------------------------\n",
    "    def check_timeout(self):\n",
    "        if self.state == ACTIVE:\n",
    "            if time.time() - self.last_active_time > self.active_timeout:\n",
    "                print(\"Auto sleep triggered.\")\n",
    "                self.deactivate()\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # LOW-POWER IDLE LISTEN LOOP\n",
    "    # ------------------------------------------------------\n",
    "    def idle_listener(self):\n",
    "        \"\"\"\n",
    "        Lightweight loop.\n",
    "        Only checks wake word.\n",
    "        ASR runs in minimal mode.\n",
    "        \"\"\"\n",
    "        print(\"Idle listener started.\")\n",
    "\n",
    "        while self.running:\n",
    "            try:\n",
    "                audio_chunk = self.audio_queue.get(timeout=1)\n",
    "\n",
    "                transcript = self.light_asr_inference(audio_chunk)\n",
    "\n",
    "                if transcript and self.check_wake_word(transcript):\n",
    "                    print(\"Wake word detected:\", transcript)\n",
    "                    self.activate()\n",
    "\n",
    "            except queue.Empty:\n",
    "                continue\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # ACTIVE LISTEN LOOP\n",
    "    # ------------------------------------------------------\n",
    "    def active_listener(self):\n",
    "        \"\"\"\n",
    "        Full ASR + intent mode.\n",
    "        \"\"\"\n",
    "        print(\"Active listener started.\")\n",
    "\n",
    "        while self.running:\n",
    "            if self.state == ACTIVE:\n",
    "                try:\n",
    "                    audio_chunk = self.audio_queue.get(timeout=1)\n",
    "\n",
    "                    transcript = self.full_asr_inference(audio_chunk)\n",
    "\n",
    "                    if transcript:\n",
    "                        print(\"Transcript:\", transcript)\n",
    "\n",
    "                        if self.check_sleep_word(transcript):\n",
    "                            print(\"Sleep word detected.\")\n",
    "                            self.deactivate()\n",
    "                            continue\n",
    "\n",
    "                        self.last_active_time = time.time()\n",
    "\n",
    "                        intent, conf = self.predict_intent(transcript)\n",
    "                        print(\"Intent:\", intent, \"Confidence:\", conf)\n",
    "\n",
    "                        # self.execute_intent(intent)\n",
    "                        self.handle_intent(intent, transcript)\n",
    "\n",
    "\n",
    "                except queue.Empty:\n",
    "                    pass\n",
    "\n",
    "            self.check_timeout()\n",
    "            time.sleep(0.05)\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # LIGHT ASR (Wake Mode)\n",
    "    # ------------------------------------------------------\n",
    "    def light_asr_inference(self, audio_chunk):\n",
    "        \"\"\"\n",
    "        Faster decode, smaller beam width.\n",
    "        \"\"\"\n",
    "        # Placeholder — connect to optimized ONNX session\n",
    "        return \"\"\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # FULL ASR (Active Mode)\n",
    "    # ------------------------------------------------------\n",
    "    def full_asr_inference(self, audio_chunk):\n",
    "        \"\"\"\n",
    "        KleidiAI optimized INT8 ONNX inference.\n",
    "        \"\"\"\n",
    "        # Convert to float32 if needed\n",
    "        input_data = np.array(audio_chunk, dtype=np.float32)\n",
    "\n",
    "        inputs = {self.asr_session.get_inputs()[0].name: input_data}\n",
    "        outputs = self.asr_session.run(None, inputs)\n",
    "\n",
    "        transcript = self.decode_output(outputs)\n",
    "        return transcript\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # OUTPUT DECODER\n",
    "    # ------------------------------------------------------\n",
    "    def decode_output(self, outputs):\n",
    "        # Replace with real decoder\n",
    "        return \"\"\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # INTENT PREDICTION\n",
    "    # ------------------------------------------------------\n",
    "    def predict_intent(self, text):\n",
    "        decision = self.intent_model.decision_function([text])\n",
    "        confidence = np.max(decision)\n",
    "        intent = self.intent_model.classes_[np.argmax(decision)]\n",
    "        return intent, confidence\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # INTENT EXECUTION\n",
    "    # ------------------------------------------------------\n",
    "    def execute_intent(self, intent):\n",
    "        print(\"Executing:\", intent)\n",
    "        # Add GPIO / system calls here\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # THREAD START\n",
    "    # ------------------------------------------------------\n",
    "    def start(self):\n",
    "        self.idle_thread = threading.Thread(target=self.idle_listener, daemon=True)\n",
    "        self.active_thread = threading.Thread(target=self.active_listener, daemon=True)\n",
    "\n",
    "        self.idle_thread.start()\n",
    "        self.active_thread.start()\n",
    "\n",
    "        print(\"Assistant threads started.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2a334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(self, text):\n",
    "    if not text:\n",
    "        return\n",
    "\n",
    "    def _speak_worker(msg):\n",
    "        if TTS_model_select == \"espeak-ng\":\n",
    "            subprocess.Popen(\n",
    "                [\"espeak-ng\", \"-v\", \"hi\", msg],\n",
    "                stdout=subprocess.DEVNULL,\n",
    "                stderr=subprocess.DEVNULL\n",
    "            )\n",
    "        elif TTS_model_select == \"festival\":\n",
    "            subprocess.Popen(\n",
    "                [\"festival\", \"--tts\"],\n",
    "                stdin=subprocess.PIPE\n",
    "            ).communicate(input=msg.encode())\n",
    "\n",
    "    threading.Thread(target=_speak_worker, args=(text,), daemon=True).start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89e47451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(self):\n",
    "    now = datetime.datetime.now()\n",
    "    response = f\"अभी समय {now.hour} बजकर {now.minute} मिनट है\"\n",
    "    self.speak(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2437d38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(self):\n",
    "    today = datetime.datetime.now()\n",
    "    response = f\"आज तारीख {today.day}-{today.month}-{today.year} है\"\n",
    "    self.speak(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88ce326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_weather(self):\n",
    "    # Replace with offline weather dataset if needed\n",
    "    self.speak(\"मौसम सामान्य है\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bfa57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_open(self):\n",
    "    subprocess.Popen([\"xdg-open\", \".\"])\n",
    "    self.speak(\"फाइल खोल दी गई है\")\n",
    "\n",
    "def file_close(self):\n",
    "    subprocess.Popen([\"pkill\", \"pcmanfm\"])\n",
    "    self.speak(\"फाइल बंद कर दी गई है\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab8185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def music_play(self):\n",
    "    subprocess.Popen([\"cvlc\", \"--random\", \"/home/pi/Music\"])\n",
    "    self.speak(\"संगीत चालू कर दिया गया है\")\n",
    "\n",
    "def music_next(self):\n",
    "    subprocess.Popen([\"pkill\", \"-SIGTERM\", \"vlc\"])\n",
    "    self.music_play()\n",
    "\n",
    "def music_stop(self):\n",
    "    subprocess.Popen([\"pkill\", \"vlc\"])\n",
    "    self.speak(\"संगीत बंद कर दिया गया है\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb912083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpio_setup(self):\n",
    "    import RPi.GPIO as GPIO\n",
    "    GPIO.setmode(GPIO.BCM)\n",
    "    GPIO.setup(GPIO_FAN, GPIO.OUT)\n",
    "    GPIO.setup(GPIO_LIGHT, GPIO.OUT)\n",
    "    self.GPIO = GPIO\n",
    "\n",
    "def fan_on(self):\n",
    "    self.GPIO.output(GPIO_FAN, True)\n",
    "    self.speak(\"पंखा चालू\")\n",
    "\n",
    "def fan_off(self):\n",
    "    self.GPIO.output(GPIO_FAN, False)\n",
    "    self.speak(\"पंखा बंद\")\n",
    "\n",
    "def light_on(self):\n",
    "    self.GPIO.output(GPIO_LIGHT, True)\n",
    "    self.speak(\"लाइट चालू\")\n",
    "\n",
    "def light_off(self):\n",
    "    self.GPIO.output(GPIO_LIGHT, False)\n",
    "    self.speak(\"लाइट बंद\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37dcc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(self, text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
    "    with torch.no_grad():\n",
    "        output = translator.generate(**inputs, max_length=64)\n",
    "    translated = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    self.speak(translated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1746fd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_search(self, query=\"\"):\n",
    "    subprocess.Popen([\"chromium-browser\", f\"https://www.google.com/search?q={query}\"])\n",
    "    self.speak(\"ब्राउज़र खोल दिया गया है\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c48f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_timer(self, seconds=10):\n",
    "    def timer_thread(sec):\n",
    "        time.sleep(sec)\n",
    "        self.speak(\"टाइमर पूरा हो गया\")\n",
    "\n",
    "    threading.Thread(target=timer_thread, args=(seconds,), daemon=True).start()\n",
    "    self.speak(\"टाइमर शुरू\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a07a983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_reminder(self, seconds=30, message=\"याद दिलाना है\"):\n",
    "    def reminder_thread(sec, msg):\n",
    "        time.sleep(sec)\n",
    "        self.speak(msg)\n",
    "\n",
    "    threading.Thread(target=reminder_thread, args=(seconds, message), daemon=True).start()\n",
    "    self.speak(\"रिमाइंडर सेट कर दिया गया है\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5812ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tell_joke(self):\n",
    "    jokes = [\n",
    "        \"टीचर: होमवर्क क्यों नहीं किया? छात्र: मैम, लाइट नहीं थी। टीचर: तो मोमबत्ती? छात्र: माचिस नहीं थी।\",\n",
    "        \n",
    "        \"डॉक्टर: आपको आराम की जरूरत है। ये नींद की गोलियाँ ले लीजिए। मरीज: डॉक्टर साहब, ये कब खानी हैं? डॉक्टर: अपनी नहीं, पत्नी की चाय में।\",\n",
    "        \n",
    "        \"पति: आज खाने में क्या है? पत्नी: जहर। पति: ठीक है, मैं देर से आऊंगा।\",\n",
    "        \n",
    "        \"बॉस: तुम्हें नौकरी से निकाला जाता है। कर्मचारी: पर क्यों? बॉस: क्योंकि तुम बहुत सवाल पूछते हो। कर्मचारी: कौन सा सवाल?\",\n",
    "        \n",
    "        \"दोस्त: भाई तू इतना पढ़ता क्यों है? दूसरा दोस्त: क्योंकि मैंने सुना है, मेहनत का फल मीठा होता है। और मुझे मीठा बहुत पसंद है।\"\n",
    "    ]\n",
    "    self.speak(np.random.choice(jokes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45134797",
   "metadata": {},
   "outputs": [],
   "source": [
    "def introduce(self):\n",
    "    self.speak(\n",
    "        \"मैं आपका ऑफलाइन हिंदी सहायक हूँ, पूरी तरह लोकल एआई पर आधारित। \"\n",
    "        \"मेरा नाम कल्पना है। मैं RAC क्लब के 3 छात्रों द्वारा बनाया गया हूँ। \"\n",
    "        \"मुझमें Python और Machine Learning के मॉडल्स इस्तेमाल किए गए हैं।\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7690288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate(self, expression):\n",
    "#     try:\n",
    "#         result = eval(expression)\n",
    "#         self.speak(f\"परिणाम है {result}\")\n",
    "#     except:\n",
    "#         self.speak(\"गणना नहीं कर पाया\")\n",
    "\n",
    "def calculate(self, text):\n",
    "\n",
    "    if not text:\n",
    "        self.speak(\"कृपया गणना बताएं\")\n",
    "        return\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Remove trigger words\n",
    "    # --------------------------------------------------\n",
    "    triggers = [\n",
    "        \"गणना करो\", \"कैल्कुलेट करो\", \"calculate\", \"ganana karo\",\n",
    "        \"calculate karo\", \"calc\", \"ganana\"\n",
    "    ]\n",
    "\n",
    "    for t in triggers:\n",
    "        text = text.replace(t, \"\")\n",
    "\n",
    "    text = text.strip()\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Number Maps (Single Digit Only)\n",
    "    # --------------------------------------------------\n",
    "    hindi_numbers = {\n",
    "        \"शून्य\": 0, \"एक\": 1, \"दो\": 2, \"तीन\": 3, \"चार\": 4,\n",
    "        \"पांच\": 5, \"छह\": 6, \"सात\": 7, \"आठ\": 8, \"नौ\": 9\n",
    "    }\n",
    "\n",
    "    english_numbers = {\n",
    "        \"zero\": 0, \"one\": 1, \"two\": 2, \"three\": 3, \"four\": 4,\n",
    "        \"five\": 5, \"six\": 6, \"seven\": 7, \"eight\": 8, \"nine\": 9\n",
    "    }\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Operator Map\n",
    "    # --------------------------------------------------\n",
    "    operators = {\n",
    "        \"plus\": \"+\", \"जोड़\": \"+\", \"प्लस\": \"+\",\n",
    "\n",
    "        \"minus\": \"-\", \"घटाना\": \"-\", \"माइनस\": \"-\",\n",
    "\n",
    "        \"multiply\": \"*\", \"multiplied\": \"*\",\n",
    "        \"गुणा\": \"*\", \"गुना\": \"*\",\n",
    "\n",
    "        \"divide\": \"/\", \"divided\": \"/\",\n",
    "        \"भागा\": \"/\", \"भगा\": \"/\"\n",
    "    }\n",
    "\n",
    "    tokens = text.split()\n",
    "\n",
    "    num1 = None\n",
    "    num2 = None\n",
    "    operator = None\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Parse Tokens\n",
    "    # --------------------------------------------------\n",
    "    for token in tokens:\n",
    "\n",
    "        # Digit direct (e.g., 7)\n",
    "        if token.isdigit():\n",
    "            val = int(token)\n",
    "            if val < 10:\n",
    "                if num1 is None:\n",
    "                    num1 = val\n",
    "                else:\n",
    "                    num2 = val\n",
    "            continue\n",
    "\n",
    "        # Hindi numbers\n",
    "        if token in hindi_numbers:\n",
    "            if num1 is None:\n",
    "                num1 = hindi_numbers[token]\n",
    "            else:\n",
    "                num2 = hindi_numbers[token]\n",
    "            continue\n",
    "\n",
    "        # English numbers\n",
    "        if token in english_numbers:\n",
    "            if num1 is None:\n",
    "                num1 = english_numbers[token]\n",
    "            else:\n",
    "                num2 = english_numbers[token]\n",
    "            continue\n",
    "\n",
    "        # Operators\n",
    "        if token in operators:\n",
    "            operator = operators[token]\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Validation\n",
    "    # --------------------------------------------------\n",
    "    if num1 is None or num2 is None or operator is None:\n",
    "        self.speak(\"सही गणना समझ नहीं पाया\")\n",
    "        return\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Safe Calculation\n",
    "    # --------------------------------------------------\n",
    "    try:\n",
    "        if operator == \"+\":\n",
    "            result = num1 + num2\n",
    "        elif operator == \"-\":\n",
    "            result = num1 - num2\n",
    "        elif operator == \"*\":\n",
    "            result = num1 * num2\n",
    "        elif operator == \"/\":\n",
    "            if num2 == 0:\n",
    "                self.speak(\"शून्य से भाग नहीं कर सकते\")\n",
    "                return\n",
    "            result = round(num1 / num2, 2)\n",
    "        else:\n",
    "            self.speak(\"ऑपरेशन समझ नहीं पाया\")\n",
    "            return\n",
    "\n",
    "        self.speak(f\"परिणाम है {result}\")\n",
    "\n",
    "    except Exception:\n",
    "        self.speak(\"गणना में त्रुटि हुई\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd78b8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_intent(self, intent, text=\"\"):\n",
    "    intent_map = {\n",
    "        \"time\": self.get_time,\n",
    "        \"date\": self.get_date,\n",
    "        \"weather\": self.check_weather,\n",
    "        \"file_open\": self.file_open,\n",
    "        \"file_close\": self.file_close,\n",
    "        \"music_play\": self.music_play,\n",
    "        \"music_next\": self.music_next,\n",
    "        \"music_stop\": self.music_stop,\n",
    "        \"gpio_fan_on\": self.fan_on,\n",
    "        \"gpio_fan_off\": self.fan_off,\n",
    "        \"gpio_light_on\": self.light_on,\n",
    "        \"gpio_light_off\": self.light_off,\n",
    "        \"translate_en\": lambda: self.translate_text(text),\n",
    "        \"web_search\": lambda: self.web_search(text),\n",
    "        \"timer\": lambda: self.set_timer(10),\n",
    "        \"reminder\": lambda: self.set_reminder(30),\n",
    "        \"tell_joke\": self.tell_joke,\n",
    "        \"introduce\": self.introduce,\n",
    "        \"calculate\": lambda: self.calculate(text)\n",
    "    }\n",
    "\n",
    "    action = intent_map.get(intent)\n",
    "    if action:\n",
    "        action()\n",
    "    else:\n",
    "        self.speak(\"समझ नहीं पाया\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba2f924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def startup_run(self):\n",
    "    self.speak(\"सिस्टम शुरू हो गया है\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9317ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(self):\n",
    "    self.startup_run()\n",
    "\n",
    "    self.start()\n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(1)\n",
    "    except KeyboardInterrupt:\n",
    "        self.running = False\n",
    "        print(\"Shutting down...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5649e160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    # ==========================================================\n",
    "    # 1️⃣ CPU PERFORMANCE OPTIMIZATION\n",
    "    # ==========================================================\n",
    "    try:\n",
    "        subprocess.run(\n",
    "            [\"sudo\", \"cpufreq-set\", \"-g\", \"performance\"],\n",
    "            stdout=subprocess.DEVNULL,\n",
    "            stderr=subprocess.DEVNULL\n",
    "        )\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = \"4\"\n",
    "    os.environ[\"TF_NUM_INTRAOP_THREADS\"] = \"4\"\n",
    "    os.environ[\"TF_NUM_INTEROP_THREADS\"] = \"1\"\n",
    "\n",
    "    # ==========================================================\n",
    "    # 2️⃣ LOAD INT8 TFLITE WITH KLEIDIAI ARM DELEGATE\n",
    "    # ==========================================================\n",
    "    print(\"Loading INT8 TFLite model with Arm Compute delegate...\")\n",
    "\n",
    "    from tflite_runtime.interpreter import Interpreter, load_delegate\n",
    "\n",
    "    delegate = load_delegate(\"libarm_delegate.so\")\n",
    "\n",
    "    interpreter = Interpreter(\n",
    "        model_path=\"models/asr_int8_quantized.tflite\",\n",
    "        experimental_delegates=[delegate],\n",
    "        num_threads=4\n",
    "    )\n",
    "\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    print(\"TFLite INT8 + KleidiAI delegate loaded.\")\n",
    "\n",
    "    # ==========================================================\n",
    "    # 3️⃣ MODEL WARM-UP (IMPORTANT FOR LATENCY)\n",
    "    # ==========================================================\n",
    "    dummy_input = np.zeros(input_details[0][\"shape\"], dtype=np.int8)\n",
    "\n",
    "    for _ in range(3):\n",
    "        interpreter.set_tensor(input_details[0][\"index\"], dummy_input)\n",
    "        interpreter.invoke()\n",
    "        _ = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "\n",
    "    print(\"Model warm-up completed.\")\n",
    "\n",
    "    # ==========================================================\n",
    "    # 4️⃣ LOAD INTENT + TTS\n",
    "    # ==========================================================\n",
    "    intent_model = preload_intent_model()\n",
    "    tts_model = preload_tts_model()\n",
    "\n",
    "    # ==========================================================\n",
    "    # 5️⃣ INITIALIZE ASSISTANT CORE\n",
    "    # ==========================================================\n",
    "    assistant = OfflineAssistant(interpreter, intent_model)\n",
    "\n",
    "    assistant.input_details = input_details\n",
    "    assistant.output_details = output_details\n",
    "\n",
    "    assistant.gpio_setup()\n",
    "\n",
    "    # ==========================================================\n",
    "    # 6️⃣ AUDIO CAPTURE THREAD (LOW LATENCY PIPELINE)\n",
    "    # ==========================================================\n",
    "    def audio_capture():\n",
    "        pa = pyaudio.PyAudio()\n",
    "\n",
    "        stream = pa.open(\n",
    "            format=pyaudio.paInt16,\n",
    "            channels=1,\n",
    "            rate=16000,\n",
    "            input=True,\n",
    "            frames_per_buffer=320\n",
    "        )\n",
    "\n",
    "        vad = webrtcvad.Vad(VAD_MODE)\n",
    "\n",
    "        while assistant.running:\n",
    "            frame = stream.read(320, exception_on_overflow=False)\n",
    "\n",
    "            if vad.is_speech(frame, 16000):\n",
    "                audio_np = np.frombuffer(frame, dtype=np.int16)\n",
    "                assistant.audio_queue.put(audio_np)\n",
    "\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        pa.terminate()\n",
    "\n",
    "    capture_thread = threading.Thread(target=audio_capture, daemon=True)\n",
    "    capture_thread.start()\n",
    "\n",
    "    # ==========================================================\n",
    "    # 7️⃣ PATCH FULL ASR INFERENCE FOR INT8 TFLITE\n",
    "    # ==========================================================\n",
    "    def tflite_asr_inference(audio_chunk):\n",
    "\n",
    "        # Normalize INT16 → INT8 input (quantized)\n",
    "        audio_float = audio_chunk.astype(np.float32) / 32768.0\n",
    "        audio_int8 = (audio_float * 127).astype(np.int8)\n",
    "\n",
    "        interpreter.set_tensor(input_details[0][\"index\"], audio_int8)\n",
    "        interpreter.invoke()\n",
    "\n",
    "        output = interpreter.get_tensor(output_details[0][\"index\"])\n",
    "\n",
    "        # Replace with real CTC decode\n",
    "        return assistant.decode_output(output)\n",
    "\n",
    "    assistant.full_asr_inference = tflite_asr_inference\n",
    "\n",
    "    # ==========================================================\n",
    "    # 8️⃣ START THREADING PIPELINE\n",
    "    # ==========================================================\n",
    "    assistant.startup_run()\n",
    "    assistant.start()\n",
    "\n",
    "    print(\"Assistant running with KleidiAI INT8 acceleration.\")\n",
    "\n",
    "    # ==========================================================\n",
    "    # 9️⃣ MAIN LOOP\n",
    "    # ==========================================================\n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(1)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        assistant.running = False\n",
    "        print(\"Shutting down assistant...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6910a59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
